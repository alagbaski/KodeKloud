#Create a deployment nagios-deployment for Nagios core.
#The container name must be nagios-container and it must use jasonrivers/nagios image.
#Create a user and password for the Nagios core web interface, user must be xFusionCorp and password must be LQfKeWWxWD. (you can manually perform this step after deployment)
#Create a service nagios-service for Nagios, which must be of targetPort type, nodePort must be 30008.

SOLUTION:
- First develop a .yaml manifest file to create a nagios deployment pod and service with the provided requirements
- You can find sample manifest file in this link ---> https://github.com/mightygull/Yaml-Manifest-Files/blob/main/Create_Nagios_Deployment.yaml
- To run the .yaml files run the command below
kubectl apply -f filename.yaml
- After creating the deployment pod and service, you have to create user and password manually
#Run the following commands to create user and password:
- Identify the pod name in which nagios was deployed into
kubectl get all
#OR
kubectl get service nagios-service
#OR
kubectl get pod
- Switch to the pod/container CLI
kubectl exec -it <nagios-pod-name> -- /bin/bash
cd /opt/nagios/etc/
htpasswd -Bc htpasswd.users <username>
- It will prompt for new password, enter the required password.
- Exit the pod/container CLI and test the Nagios web interface on the terminal
==========================================================================================================================================================================================
#Install apache2 in "kkloud" container using apt that is running on App Server 3 in Stratos Datacenter
#Configure Apache to listen on port 5004 instead of default http port. Do not bind it to listen on specific IP or hostname only, 
(i.e it should listen on localhost, 127.0.0.1, container ip, etc)
#Make sure Apache service is up and running inside the container.
#Keep the container in running state at the end.

SOLUTION:
- First switch to pod/container CLI in the required App Server.
sudo docker exec -it kkloud /bin/bash
apt install apache2 -y
apt install nano
- Also while in pod CLI configure the apache2 service to Listen on the required port.
sudo nano /etc/apache2/ports.conf
- Look for the line that has Listen and modifiy to "Listen = 5004".
- Exit the editor and the restart service.
service apache2 restart
service apache2 status
- Exit the container/pod CLI, then check if the container is in running state.
exit
sudo docker ps
================================================================================================================================================================================
#Create a pod named "pod-httpd" using httpd image with latest tag only and remember to mention the tag (httpd:latest).
#Labels app should be set to "httpd_app", also container should be named as "httpd-container".

SOLUTION:
- Create a .yaml manifest file to create the pod/container using the requirements given.
- You can find sample of the manifest file in this link ---> https://github.com/mightygull/Yaml-Manifest-Files/blob/main/Create_Pod.yaml
- To execute the .yaml file, Run:
kubectl create -f filename.yaml
- Confirm if the pod is created and ready.
kubectl get pod
===================================================================================================================================================================================
#Create a generic secret named "news", it should contain the password/license-number present in news.txt file.
#We already have a secret key file "news.txt" under /opt location on jump host.
#Also create a pod named "secret-xfusion".
#Configure pod's spec as container name should be "secret-container-xfusion", image should be "fedora" preferably with latest tag (remember to mention the tag with image).
#Use sleep command for container so that it remains in running state.
#Consume the created secret and mount it under "/opt/apps" within the container.
#Verify to check the secret key under the mounted path "/opt/apps".
#Please make sure pod/pods are in running state, also validation can take some time to complete so keep patience.

SOLUTION:
- First develop the YAML manifest for creating the secret and the pod as per your requirements.
- You can find sample manifest file in this link ---> https://github.com/mightygull/Yaml-Manifest-Files/blob/main/Create_Secrets_Pod.yaml
- Before applying the manifest file, look for the line that has "<base64-encoded content of news.txt>" and replace it with the base64-encoded content of the beta.txt file.
- You can encode the file content using the "base64" command-line tool in the /opt.
- Do so by running the command below:
base64 -w 0 news.txt
- Here's an example of how the encoded content would look (NWVjdXIzCg==).
- Replace <base64-encoded content of news.txt> in the already developed manifest with the actual base64-encoded content that you obtained.
- Then apply the .yaml manifest file.
kubectl apply -f filename.yaml
- To verify you can exec into the container to check.
kubectl exec -it secret-xfusion -c secret-container-xfusion -- /bin/bash
ls /opt/apps/news.txt
- To make sure pod/pods are in running state.
kubectl get pods
=================================================================================================================================================================================
#Create a namespace "jenkins".
#Create a Service for jenkins deployment, service name should be "jenkins-service" under jenkins namespace, type should be NodePort, nodePort should be "30008".
#Create a Jenkins Deployment under jenkins namespace.
- It should be name as jenkins-deployment.
- Labels app should be jenkins.
- Container name should be jenkins-container.
- Use jenkins/jenkins image.
- ContainerPort should be 8080 and replicas count should be 1.
#Make sure you are able to access the Jenkins login screen in the browser.

SOLUTION:
- Create the YAML manifest to create the namespace, service, and deployment for Jenkins as per your requirements.
- You can find sample manifest files in this link ---> https://github.com/mightygull/Yaml-Manifest-Files/tree/main/create-namespace-deployment-services-jenkins
- Save the above YAML manifests into separate files (e.g., jenkins-namespace.yaml, jenkins-service.yaml, jenkins-deployment.yaml).
- Run the following commands to execute the rest of the task:
kubectl apply -f jenkins-namespace.yaml
kubectl apply -f jenkins-service.yaml
kubectl apply -f jenkins-deployment.yaml

#Make sure to wait for the pods to be in running state.
- To check the pod status, Run:
kubectl get pods -n jenkins
=================================================================================================================================================================
#Manage all servers within the stack using Ansible, the Nautilus DevOps team is planning to use a common sudo user among all servers.
#On jump host make appropriate changes so that Ansible can use james as a default ssh user for all hosts.
#Make changes in Ansible's default configuration only â€”please do not try to create a new config.

SOLUTION:
- Locate the Ansible configuration file, typically located at /etc/ansible/ansible.cfg.
sudo vi /etc/ansible/ansible.cfg
- Uncomment or add the following line within the [defaults] section:
remote_user = james
- Save and exit editor.
- Verify that the changes have been applied by running the following command:
ansible-config dump | grep REMOTE_USER
=====================================================================================================================================================================================
#Create a redis deployment with following parameters:
- Create a config map called "my-redis-config" having maxmemory 2mb in redis-config.
- Name of the deployment should be "redis-deployment", it should use "redis:alpine" image and container name should be "redis-container".
- Also make sure it has only 1 replica.
- The container should request for 1 CPU.
- Mount 2 volumes:
a.An Empty directory volume called data at path /redis-master-data.
b.A configmap volume called redis-config at path /redis-master.
c.The container should expose the port 6379.
- Finally, redis-deployment should be in an up and running state.

SOLUTION:
- You need to generate a .yaml manifest to carry-out all the requirements of the task.
- You can find the sample of the manifest i used in this link ----> https://github.com/mightygull/Yaml-Manifest-Files/blob/main/create_redis_deployment-config-map.yaml
- Apply the .yaml manifest.
kubectl apply -f filename.yaml
- To ensure that the Redis deployment is up and running, you can follow these steps:
kubectl get deployments
kubectl get pods
kubectl logs <redis-pod-name>
===========================================================================================================================================================================
#Using Puppet file resource and perform the below given task:
#Create a Puppet programming file "ecommerce.pp" under /etc/puppetlabs/code/environments/production/manifests directory on master node.
#Using /etc/puppetlabs/code/environments/production/manifests/ecommerce.pp create a file "blog.txt" under "/opt/itadmin" directory on App Server 2.
#NB:
- Please make sure to run the puppet agent test using sudo on agent nodes, otherwise you can face certificate issues.
- In that case you will have to clean the certificates first and then you will be able to run the puppet agent test.
- Please make sure to verify puppet server and puppet agent services are up and running on the respective servers.
- Also please make sure to run puppet agent test to apply/test the changes manually first.

SOLUTION:
- Create a file named ecommerce.pp under the /etc/puppetlabs/code/environments/production/manifests directory.
cd /etc/puppetlabs/code/environments/production/manifests
sudo vi ecommerce.pp
- Add the Puppet code to create the blog.txt file on App Server 2 under the /opt/itadmin directory.

file { '/opt/itadmin/blog.txt':
  ensure => present,
  content => 'This is a sample news file created by Puppet.',
  owner  => 'root',
  group  => 'root',
  mode   => '0644',
}

#This code defines a file resource that ensures the presence of the blog.txt file with the specified content, ownership, group, and permissions.
- Save and exit editor
- Run the Puppet agent test manually on App Server 2 using the following command with sudo:
sudo puppet agent -t
#Running this command will apply the Puppet configurations on the agent node and create the blog.txt file under /opt/itadmin according to the specifications in ecommerce.pp
- Please note that if you encounter any certificate issues, you may need to clean the certificates before running the Puppet agent test.
#To verify the status of the Puppet services on the agent nodes, you can use the appropriate command for your operating system.
Here are the commands for some common operating systems:
- Systemd-based systems (e.g., Ubuntu, CentOS 7 and above):
sudo systemctl status puppet
sudo systemctl start puppet
sudo systemctl stop puppet
- Init.d-based systems (e.g., CentOS 6):
service puppet status
service puppet start
service puppet stop
- Windows:
sc query puppet
net start puppet
net stop puppet
=======================================================================================================================================================================================
#Create a deployment named nginx to deploy the application nginx using the image nginx:latest (remember to mention the tag as well).

SOLUTION:
- Develop a manifest file to create  a deploymnt as per details mentioned.
- The sample of the .yaml file can be found in this link ---> https://github.com/mightygull/Yaml-Manifest-Files/blob/main/Create-Nginx-Deployment.yaml
- After creating and adding the requirments for the deployment in the manifest, Run the command to execute the task.
kubectl apply -f filename.yaml
==================================================================================================================================================================================
#Create an inventory file ~/playbook/inventory on jump host and add all app servers in it.
#Create a playbook ~/playbook/playbook.yml to create a blank file /opt/opt.txt on all app servers.
#The /opt/opt.txt file permission must be 0744.
#The user/group owner of file /opt/opt.txt must be tony on app server 1, steve on app server 2 and banner on app server 3.

//SOLUTION:
- cd into playbook folder and create the inventory file.
vi inventory
- Paste the following in it and save.
[all]
stapp01 ansible_user=tony ansible_password=Ir0nM@n
stapp02 ansible_user=steve ansible_password=Am3ric@
stapp03 ansible_user=banner ansible_password=BigGr33n

- Create the playbook for creating the blank file and granting permission "0744"
- The sample of the playbook.yml can be found in this link ---> https://github.com/mightygull/Ansible-Playbooks/blob/main/Create%20File%20On%20Diff%20Servers%20%26%20Set%20Ownership.yml
#run playbook
ansible-playbook -i inventory playbook.yml
================================================================================================================================================================================
#Creating some cron jobs in Kubernetes cluster with some dummy commands (which will be replaced by original scripts later).
#Create a cronjob as per details given below:
- Create a cronjob named nautilus.
- Set schedule to */5 * * * *.
- Container name should be cron-nautilus.
- Use nginx image with latest tag only and remember to mention the tag i.e nginx:latest.
- Run a dummy command echo Welcome to xfusioncorp!.
- Ensure restart policy is OnFailure.

//SOLUTION:
#Create YAML configuration for creating the cron job based on the details you provided.
- You can find the sample of the manifest in this link ---> https://github.com/mightygull/Yaml-Manifest-Files/blob/main/Create-Cronjobs-In-Kubernetes.yaml
#Apply the created .yaml manifest file for creating the cronjobs on the cluster.
kubectl create -f filename.yaml
=============================================================================================================================================================================
#Create a Puppet programming file apps.pp under /etc/puppetlabs/code/environments/production/manifests directory on master node i.e Jump Server.
#And using Puppet user resource add a user on all app servers as mentioned below:
- Create a user "ammar" and set its UID to "1207" on Puppet agent node 2 i.e App Servers 2.
- Please make sure to run puppet agent test to apply/test the changes manually.
- Also, make sure to verify puppet server and puppet agent services are up and running on the respective servers.

//SOLUTION:
#Navigate to the /etc/puppetlabs/code/environments/production/manifests directory.
cd /etc/puppetlabs/code/environments/production/manifests
sudo nano apps.pp
#Add the following code to the "apps.pp" file to define the user resource for "ammar" with the specified UID.

node 'app-server 2' {
  user { 'ammar':
    ensure => present,
    uid    => '1207',
  }
}

- Replace 'app-server 2' with the actual Puppet node name or hostname of App Server 2 where you want to create the user.
# Start Puppet server.
sudo systemctl start puppetserver
sudo systemctl status puppetserver
#SSH into app-server 2.
# Start Puppet agent.
sudo systemctl start puppet  
sudo systemctl status puppet
#Run puppet agent test to apply/test the changes manually on App Server 2.
sudo puppet agent -t
- NB: Please make sure to run the puppet agent test using sudo on agent nodes, otherwise you can face certificate issues.
In that case you will have to clean the certificates first and then you will be able to run the puppet agent test.
===========================================================================================================================================================================
#We have some conditional data present on App Server 3 in Stratos Datacenter. 
#There is a container "ubuntu_latest" running on the same server.
- On App Server 3 in Stratos Datacenter copy an encrypted file /tmp/nautilus.txt.gpg from docker host to ubuntu_latest container (running on same server) in /usr/src/ location.

//SOLUTION:
- Make sure the container ubuntu_latest is running on the server.
docker ps
- After confirming, use the "docker cp" command to copy the encrypted file from the Docker host to the container.
docker cp /tmp/nautilus.txt.gpg ubuntu_latest:/usr/src/
==============================================================================================================================================================
#The Nautilus application development team has been working on a project repository /opt/ecommerce.git.
#This repo is cloned at "/usr/src/kodekloudrepos" on storage server in Stratos DC.
- Create a new branch "xfusion" in /usr/src/kodekloudrepos/official repo from master and copy the /tmp/index.html file (on storage server itself).
- Add/commit this file in the new branch and merge back that branch to the master branch.
- Finally, push the changes to origin for both of the branches.

//SOLUTION:
#Change to the directory where the ecommerce repository is located.
cd /usr/src/kodekloudrepos/ecommerce/
#Create a new branch called "xfusion" from the "master" branch
git branch  -----> To check the current branch, make sure it is at master branch.
sudo git branch xfusion
sudo git checkout xfusion
#Copy the "/tmp/index.html" file to the new branch
sudo cp /tmp/index.html .
#Add & Commit the copied file to the Git index.
sudo git add .
sudo git commit -m "Added index.html to xfusion branch"
#Merge the "xfusion" branch into the "master" branch and push the changes to the "origin" repository for both branches.
sudo git checkout master
sudo git merge xfusion
sudo git push origin master xfusion
====================================================================================================================================================================================
#There are some packages that need to be installed on the app server 1.
#We want to install these packages using puppet only.
#Create a puppet programming file blog.pp under /etc/puppetlabs/code/environments/production/manifests on master node and perform below mentioned tasks using the same.
- Define a class multi_package_node for agent node 1 (App Server 1).
- Install net-tools and unzip packages on the agent node 1.
- Make sure to run puppet agent test to apply/test the changes manually.
- Also, make sure to verify puppet server and puppet agent services are up and running on the respective servers.

//SOLUTION:
#Navigate to the Puppet manifests directory.
cd /etc/puppetlabs/code/environments/production/manifests
#Create a new Puppet programming file called blog.pp, in the blog.pp file, define the class and specify the packages to be installed.
sudo vi blog.pp
#You can find the sample of the puppet file in this link ---> https://github.com/mightygull/Puppet-Files/blob/main/install_multi_package_node.pp
#Now, you need to assign this class to the agent node (App Server 1). To do that, create a new file called site.pp in the same directory.
sudo vi site.pp
#In the "site.pp" file, assign the multi_package_node class to the agent node (App Server 1) by adding the following code:

node 'agent_node1.example.com' {
  include multi_package_node
}

- Replace 'agent_node1.example.com' with the actual hostname of your agent node (App Server 1).
- Save and exit the file.
#Trigger a Puppet run on the agent node (App Server 1) to apply the configuration changes.
sudo puppet agent -t
=================================================================================================================================================================================
#Rolling Updates And Rolling Back Deployments in Kubernetes.
#The Nautilus DevOps team wants to test the deployment update and rollback on Dev environment first so that they can identify the risks in advance.
- Create a namespace called "devops".
- Create a deployment called "httpd-deploy" under this new namespace, It should have one container called "httpd", use "httpd:2.4.28" image and 3 replicas.
- The deployment should use RollingUpdate strategy with maxSurge=1, and maxUnavailable=2.
- Create a NodePort type service named httpd-service and expose the deployment on nodePort: 30008.
#Upgrade the deployment to version httpd:2.4.43 using a rolling update, once all pods are updated undo the recent update and roll back to the previous/original version.

//SOLUTION:
#Create namespace
kubectl create namespace devops
#Create the deployment under the namespace according to its requirments.
kubectl create deployment httpd-deploy --image=httpd:2.4.28 --replicas=3 -n devops
OR
- Sample of the yaml file can be found in this link ---> https://github.com/mightygull/Yaml-Manifest-Files/blob/main/Rolling-Update%26Back-Deployment.yaml
#Create the service and expose the node port as per requirments.
- Sample of the yaml file can be found in this link ---> https://github.com/mightygull/Yaml-Manifest-Files/blob/main/Create-Namespace-Deployment-Services-Jenkins/Create-Service.yaml
#You can retrieve the assigned nodePort by running the following command.
kubectl get service httpd-service -n devops
#Configure the RollingUpdate strategy for the deployment. 
kubectl set image deployment/httpd-deploy httpd=httpd:2.4.43 -n devops
=NB= [If you use the yaml deployment link above you dont have to run the command, just use a text editor and modify the image and apply after saving the modification]
#Wait for the pods to be updated to the new version.
kubectl rollout status deployment/httpd-deploy -n devops
#To check if all pods are updated and running after the deployment update.
kubectl get pods -n devops
OR
kubectl describe pods -n devops
#To roll back the deployment and revert to the previous/original version, you can use the following command.
kubectl rollout undo deployment/httpd-deploy -n devops
kubectl rollout status deployment/httpd-deploy -n devops
=====================================================================================================================================================================================
#Git Clone Repositories. The Nautilus application development team recently asked for a copy of that repo on Storage server in Stratos DC.
#The repo that needs to be cloned is "/opt/apps.git"
#Clone this git repository under /usr/src/kodekloudrepos directory.

//SOLUTION:
- Navigate to the directory where you want to clone the repository.
cd /usr/src/kodekloudrepos
- Run the following command to clone the git repo.
sudo git clone /opt/apps.git
=====================================================================================================================================================================================
